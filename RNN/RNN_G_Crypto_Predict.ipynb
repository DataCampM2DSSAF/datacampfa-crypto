{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install jovian opendatasets matplotlib seaborn xgboost --upgrade --quiet\n","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:47:35.281981Z","iopub.execute_input":"2022-03-23T14:47:35.282533Z","iopub.status.idle":"2022-03-23T14:47:47.515801Z","shell.execute_reply.started":"2022-03-23T14:47:35.282479Z","shell.execute_reply":"2022-03-23T14:47:47.514727Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Import packages\nimport opendatasets as od\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\n\nfrom datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:48:01.324170Z","iopub.execute_input":"2022-03-23T14:48:01.324990Z","iopub.status.idle":"2022-03-23T14:48:01.331782Z","shell.execute_reply.started":"2022-03-23T14:48:01.324946Z","shell.execute_reply":"2022-03-23T14:48:01.330921Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data_url = 'https://www.kaggle.com/c/g-research-crypto-forecasting/data'\nod.download(data_url)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:48:03.499442Z","iopub.execute_input":"2022-03-23T14:48:03.500565Z","iopub.status.idle":"2022-03-23T14:48:03.506334Z","shell.execute_reply.started":"2022-03-23T14:48:03.500521Z","shell.execute_reply":"2022-03-23T14:48:03.505313Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"data_dir = './g-research-crypto-forecasting'\nos.listdir(data_dir)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:48:05.545642Z","iopub.execute_input":"2022-03-23T14:48:05.545965Z","iopub.status.idle":"2022-03-23T14:48:05.553085Z","shell.execute_reply.started":"2022-03-23T14:48:05.545934Z","shell.execute_reply":"2022-03-23T14:48:05.552218Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('./g-research-crypto-forecasting/train.csv')\nasset_details_df = pd.read_csv('./g-research-crypto-forecasting/asset_details.csv')\ntest_df = pd.read_csv('./g-research-crypto-forecasting/example_test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:57:20.170071Z","iopub.execute_input":"2022-03-23T14:57:20.171015Z","iopub.status.idle":"2022-03-23T14:57:59.783571Z","shell.execute_reply.started":"2022-03-23T14:57:20.170968Z","shell.execute_reply":"2022-03-23T14:57:59.782397Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## RNN-LSTM Crypto-forcasting\n","metadata":{}},{"cell_type":"code","source":"import os\nimport IPython\nimport IPython.display\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn import metrics\nmpl.rcParams['figure.figsize'] = (8, 6)\nmpl.rcParams['axes.grid'] = False\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:49:09.544185Z","iopub.execute_input":"2022-03-23T14:49:09.544651Z","iopub.status.idle":"2022-03-23T14:49:09.554019Z","shell.execute_reply.started":"2022-03-23T14:49:09.544612Z","shell.execute_reply":"2022-03-23T14:49:09.552636Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Missing data","metadata":{}},{"cell_type":"code","source":"for i in range(0,14):\n    train_df[train_df[\"Asset_ID\"] ==i].reindex(range(train_df[train_df[\"Asset_ID\"] ==i].index[0],train_df[train_df[\"Asset_ID\"] ==i].index[-1]+60,60),method='pad')\n","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:49:12.140706Z","iopub.execute_input":"2022-03-23T14:49:12.141497Z","iopub.status.idle":"2022-03-23T14:49:30.177689Z","shell.execute_reply.started":"2022-03-23T14:49:12.141414Z","shell.execute_reply":"2022-03-23T14:49:30.176689Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_df.dropna(inplace=True)\ntrain_df = train_df[np.isfinite(train_df).all(1)]","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:49:35.370578Z","iopub.execute_input":"2022-03-23T14:49:35.372032Z","iopub.status.idle":"2022-03-23T14:49:41.091414Z","shell.execute_reply.started":"2022-03-23T14:49:35.371974Z","shell.execute_reply":"2022-03-23T14:49:41.090330Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:45:28.167091Z","iopub.execute_input":"2022-03-23T16:45:28.167408Z","iopub.status.idle":"2022-03-23T16:45:28.174063Z","shell.execute_reply.started":"2022-03-23T16:45:28.167378Z","shell.execute_reply":"2022-03-23T16:45:28.173058Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"df.isin([np.nan, np.inf, -np.inf]).sum()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:48:15.446851Z","iopub.execute_input":"2022-03-23T16:48:15.447177Z","iopub.status.idle":"2022-03-23T16:48:15.609217Z","shell.execute_reply.started":"2022-03-23T16:48:15.447145Z","shell.execute_reply":"2022-03-23T16:48:15.607897Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)\ndf = train_df[np.isfinite(train_df).all(1)]","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:48:12.383797Z","iopub.execute_input":"2022-03-23T16:48:12.384183Z","iopub.status.idle":"2022-03-23T16:48:12.736412Z","shell.execute_reply.started":"2022-03-23T16:48:12.384149Z","shell.execute_reply":"2022-03-23T16:48:12.735127Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"24236806//10 ","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:10.780877Z","iopub.execute_input":"2022-03-23T14:59:10.781996Z","iopub.status.idle":"2022-03-23T14:59:10.788954Z","shell.execute_reply.started":"2022-03-23T14:59:10.781947Z","shell.execute_reply":"2022-03-23T14:59:10.788017Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"df = train_df[-2423680:]","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:20.641439Z","iopub.execute_input":"2022-03-23T14:59:20.642652Z","iopub.status.idle":"2022-03-23T14:59:20.648352Z","shell.execute_reply.started":"2022-03-23T14:59:20.642579Z","shell.execute_reply":"2022-03-23T14:59:20.647077Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:22.844469Z","iopub.execute_input":"2022-03-23T14:59:22.844878Z","iopub.status.idle":"2022-03-23T14:59:22.852079Z","shell.execute_reply.started":"2022-03-23T14:59:22.844836Z","shell.execute_reply":"2022-03-23T14:59:22.851283Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"## Train test split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef mysplit(df,features, **split_para):\n    df = df[features]\n    train_df,val_df = train_test_split(df,train_size=split_para['train_size'],\n                                                test_size=split_para['val_size'],shuffle=False)\n    #holdout/test sets\n    n = len(df) #rows\n    test_start = int(n*(1-split_para['train_size']-split_para['val_size']))\n    test_df = df[test_start:]\n\n    return train_df, val_df, test_df","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:25.963457Z","iopub.execute_input":"2022-03-23T14:59:25.963993Z","iopub.status.idle":"2022-03-23T14:59:25.971006Z","shell.execute_reply.started":"2022-03-23T14:59:25.963957Z","shell.execute_reply":"2022-03-23T14:59:25.970087Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"train_df, val_df, test_df = mysplit(df= df, features =['Count','Open','High','Low','Close','Volume','VWAP']\n                                    ,train_size=0.7,val_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:30.874072Z","iopub.execute_input":"2022-03-23T14:59:30.875320Z","iopub.status.idle":"2022-03-23T14:59:31.251176Z","shell.execute_reply.started":"2022-03-23T14:59:30.875253Z","shell.execute_reply":"2022-03-23T14:59:31.250170Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"train_mean = train_df.mean()\ntrain_std = train_df.std()\n\ntrain_df = (train_df - train_mean) / train_std #scipy.stats.zscore(train_df,ddof=1)\nval_df = (val_df - train_mean) / train_std\ntest_df = (test_df - train_mean) / train_std","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:33.110893Z","iopub.execute_input":"2022-03-23T14:59:33.111710Z","iopub.status.idle":"2022-03-23T14:59:33.341793Z","shell.execute_reply.started":"2022-03-23T14:59:33.111653Z","shell.execute_reply":"2022-03-23T14:59:33.341074Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"train_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:35.511401Z","iopub.execute_input":"2022-03-23T14:59:35.512307Z","iopub.status.idle":"2022-03-23T14:59:35.533839Z","shell.execute_reply.started":"2022-03-23T14:59:35.512260Z","shell.execute_reply":"2022-03-23T14:59:35.532598Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"## Writting the model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n#########################initial the class\nclass WindowGenerator():\n  def __init__(self, input_width, label_width, shift, train_df, val_df, test_df,\n               label_columns=None,**kwargs):\n    # Store the raw data.\n    self.train_df = train_df\n    self.val_df = val_df\n    self.test_df = test_df\n\n    # Work out the label column indices.\n    self.label_columns = label_columns\n    if label_columns is not None:\n      self.label_columns_indices = {name: i for i, name in\n                                    enumerate(label_columns)}\n    self.column_indices = {name: i for i, name in\n                           enumerate(train_df.columns)}\n\n    # Work out the window width.\n    self.input_width = input_width\n    self.label_width = label_width\n    self.shift = shift #offset size\n    self.total_window_size = input_width + shift\n\n    #input/label index and slice\n    self.input_slice = slice(0, input_width)\n    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n    self.label_start = self.total_window_size - self.label_width\n    self.labels_slice = slice(self.label_start, None)\n    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n\n  def __repr__(self):\n    ##display output\n    return '\\n'.join([\n        f'Input width={self.input_width},Label width={self.label_width},Offset width={self.shift}',\n        f'Total window size: {self.total_window_size}',\n        f'Input indices: {self.input_indices}',\n        f'Label indices: {self.label_indices}',\n        f'Label column name(s): {self.label_columns}'])\n\n##############################methods: make_dataset\ndef split_window(self, features):\n  '''\n  Given a list of consecutive inputs, the split_window method will convert \n        them to a window of inputs and a window of labels.\n  '''\n  inputs = features[:, self.input_slice, :]\n  labels = features[:, self.labels_slice, :]\n  if self.label_columns is not None:\n    labels = tf.stack(\n        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n        axis=-1)\n\n  # Slicing doesn't preserve static shape information, so set the shapes\n  # manually. This way the `tf.data.Datasets` are easier to inspect.\n  inputs.set_shape([None, self.input_width, None])\n  labels.set_shape([None, self.label_width, None])\n\n  return inputs, labels\n\ndef make_dataset(self, data):\n  '''\n  take a time series DataFrame and convert it to a tf.data.Dataset of (input_window, label_window) pairs \n    using the `preprocessing.timeseries_dataset_from_array`.\n  `timeseries_dataset_from_array`: Creates a dataset of sliding windows over a timeseries provided as array.\n      - `batch_size` only matters when want to control the size of the sample network read in at each time.\n      - a batch results in only one update to the model.\n  '''\n  data = np.array(data, dtype=np.float32)\n  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n      data=data,\n      targets=None,\n      sequence_length=self.total_window_size,\n      sequence_stride=1,\n      shuffle=False,\n      batch_size=32,)\n  #splits input and label over all batchs in the ds\n  ds = ds.map(self.split_window)\n  return ds\n\nWindowGenerator.split_window = split_window\nWindowGenerator.make_dataset = make_dataset\n##############################add method as property\n@property\ndef train(self):\n  return self.make_dataset(self.train_df)\n\n@property\ndef val(self):\n  '''\n  split with validation part helps the overfitting problem\n  '''\n  return self.make_dataset(self.val_df)\n\n@property\ndef test(self):\n  return self.make_dataset(self.test_df)\n\n@property\ndef example(self):\n  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n  result = getattr(self, '_example', None)\n  if result is None:\n    # No example batch was found, so get one from the `.train` dataset\n    result = next(iter(self.train))\n    # And cache it for next time\n    self._example = result\n  return result\n\nWindowGenerator.train = train\nWindowGenerator.val = val\nWindowGenerator.test = test\nWindowGenerator.example = example\n##############################add method plot as property\ndef plot(self, model=None, plot_col='Close', max_subplots=3):\n  inputs, labels = self.example\n  plt.figure(figsize=(12, 8))\n  plot_col_index = self.column_indices[plot_col]\n  max_n = min(max_subplots, len(inputs))\n  for n in range(max_n):\n    plt.subplot(max_n, 1, n+1)\n    plt.ylabel(f'{plot_col} [normed]')\n    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n             label='Inputs', marker='.', zorder=-10)\n\n    if self.label_columns:\n      label_col_index = self.label_columns_indices.get(plot_col, None)\n    else:\n      label_col_index = plot_col_index\n\n    if label_col_index is None:\n      continue\n\n    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n    if model is not None:\n      predictions = model(inputs)\n      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n                  marker='X', edgecolors='k', label='Predictions',\n                  c='#ff7f0e', s=64)\n\n    if n == 0:\n      plt.legend()\n\n  plt.xlabel('Time [m]')\n\nWindowGenerator.plot = plot","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:37.390390Z","iopub.execute_input":"2022-03-23T14:59:37.390805Z","iopub.status.idle":"2022-03-23T14:59:37.427527Z","shell.execute_reply.started":"2022-03-23T14:59:37.390768Z","shell.execute_reply":"2022-03-23T14:59:37.426321Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom datetime import datetime\n\ndef compile_and_fit(model, window, **compilefitpara):\n  '''\n  model could be a pretrained or new \n  '''\n  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                      patience=2,\n                                                      mode='min',restore_best_weights=False)\n  #Configures the model for training.\n  if 'pretrained' not in compilefitpara:\n    print('Compile...')\n    model.compile(loss=tf.losses.MeanSquaredError(),\n                  optimizer=tf.optimizers.Adam(),\n                  metrics=[tf.metrics.MeanAbsoluteError(),'mse'])\n    print('Train...')\n    history = model.fit(window.train, epochs=compilefitpara['MAX_EPOCHS'],\n                        validation_data=window.val,\n                        verbose = compilefitpara['verbose'],\n                        callbacks=[early_stopping])\n  elif compilefitpara['pretrained']:\n    print('Updating pretrained model...')\n    history = model.fit(window.train, epochs=compilefitpara['MAX_EPOCHS'],\n                            validation_data=window.val,\n                            verbose = 0,\n                            callbacks=[early_stopping])\n  return history","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:48.425993Z","iopub.execute_input":"2022-03-23T14:59:48.427203Z","iopub.status.idle":"2022-03-23T14:59:48.438487Z","shell.execute_reply.started":"2022-03-23T14:59:48.427138Z","shell.execute_reply":"2022-03-23T14:59:48.437518Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"'''\nwindowing + model.compile+model.fit\n'''\n\n\ndef mymodel():\n    '''\n    design the base lstm models for compile and fit\n    '''\n    model_list = []\n    ## model1 single time-step\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.LSTM(units = 20, return_sequences=True,\n                            activation='tanh', recurrent_activation='sigmoid'))\n    model.add(tf.keras.layers.Dense(units=1))\n    model_list.append(model)\n    ## model2 multiple time-step\n    \n    return model_list\n\ndef myfittedmodel(model,**windowpara):\n    # windowing\n    wide_window = WindowGenerator(**windowpara)\n    # fit the model\n    if 'type' not in windowpara:\n        history = compile_and_fit(model = model, window = wide_window, \n                                    MAX_EPOCHS = 2,verbose=0)\n    elif windowpara['type'] =='update':\n        history = compile_and_fit(model = model, window = wide_window, \n                                    MAX_EPOCHS = 2,verbose=0, pretrained=True)\n    return wide_window,model","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:51.333073Z","iopub.execute_input":"2022-03-23T14:59:51.333430Z","iopub.status.idle":"2022-03-23T14:59:51.343425Z","shell.execute_reply.started":"2022-03-23T14:59:51.333396Z","shell.execute_reply":"2022-03-23T14:59:51.342360Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"## Model design and fit\n","metadata":{}},{"cell_type":"code","source":"#model design and fit\n\nmylstm = mymodel()\nwide_window,lstm_model = myfittedmodel(model = mylstm[0], input_width=30, label_width=30, shift=1,\n                                                train_df=train_df, val_df=val_df, test_df=test_df,\n                                                label_columns=['Close'])\nIPython.display.clear_output()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:59:54.756965Z","iopub.execute_input":"2022-03-23T14:59:54.757327Z","iopub.status.idle":"2022-03-23T15:24:02.547513Z","shell.execute_reply.started":"2022-03-23T14:59:54.757290Z","shell.execute_reply":"2022-03-23T15:24:02.546588Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"print('Input shape:', wide_window.example[0].shape)#[batch_size, timesteps, feature]\nprint('Output shape:', lstm_model(inputs= wide_window.example[0]).shape)\nprint('Label shape:', wide_window.example[1].shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:24:29.298191Z","iopub.execute_input":"2022-03-23T15:24:29.298743Z","iopub.status.idle":"2022-03-23T15:24:29.553192Z","shell.execute_reply.started":"2022-03-23T15:24:29.298699Z","shell.execute_reply":"2022-03-23T15:24:29.552517Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the architecture","metadata":{}},{"cell_type":"code","source":"lstm_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:24:31.824172Z","iopub.execute_input":"2022-03-23T15:24:31.824663Z","iopub.status.idle":"2022-03-23T15:24:31.833287Z","shell.execute_reply.started":"2022-03-23T15:24:31.824630Z","shell.execute_reply":"2022-03-23T15:24:31.832524Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"### Performence Metric","metadata":{}},{"cell_type":"code","source":"val_performance={}\nperformance={}\nval_performance['LSTM0'] = lstm_model.evaluate(x = wide_window.val,verbose=0)\nperformance['LSTM0'] = lstm_model.evaluate(wide_window.test, verbose=0,return_dict=False)\nlstm_model.metrics_names\n","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:33:39.417718Z","iopub.execute_input":"2022-03-23T15:33:39.418136Z","iopub.status.idle":"2022-03-23T15:41:08.698411Z","shell.execute_reply.started":"2022-03-23T15:33:39.418097Z","shell.execute_reply":"2022-03-23T15:41:08.697612Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"performance['LSTM0']#test evaluation","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:44:47.990323Z","iopub.execute_input":"2022-03-23T15:44:47.990730Z","iopub.status.idle":"2022-03-23T15:44:47.999194Z","shell.execute_reply.started":"2022-03-23T15:44:47.990693Z","shell.execute_reply":"2022-03-23T15:44:47.997772Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"val_performance['LSTM0']#val/train evaluation","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:44:50.646974Z","iopub.execute_input":"2022-03-23T15:44:50.647572Z","iopub.status.idle":"2022-03-23T15:44:50.654876Z","shell.execute_reply.started":"2022-03-23T15:44:50.647521Z","shell.execute_reply":"2022-03-23T15:44:50.654043Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"### tf.keras.loss version","metadata":{}},{"cell_type":"code","source":"x = np.arange(len(performance))\nwidth = 0.3\nmetric_name = 'mean_absolute_error'\nmae_index = lstm_model.metrics_names.index('mean_absolute_error')\nval_mae = [v[mae_index] for v in val_performance.values()]\ntest_mae = [v[mae_index] for v in performance.values()]\n\nplt.ylabel('mean_absolute_error [Close, normalized]')\nplt.bar(x - 0.17, val_mae, width, label='Validation')\nplt.bar(x + 0.17, test_mae, width, label='Test')\nplt.xticks(ticks=x, labels=performance.keys(),\n           rotation=45)\n_ = plt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:44:59.138177Z","iopub.execute_input":"2022-03-23T15:44:59.138529Z","iopub.status.idle":"2022-03-23T15:44:59.393421Z","shell.execute_reply.started":"2022-03-23T15:44:59.138495Z","shell.execute_reply":"2022-03-23T15:44:59.392359Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"# save entire network to HDF5 \nsave_path = \"/D:/Master/RNN_Crypto\"\nlstm_model.save(os.path.join(save_path,\"lstm-base.h5\"))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:57:24.769292Z","iopub.execute_input":"2022-03-23T15:57:24.769630Z","iopub.status.idle":"2022-03-23T15:57:24.796098Z","shell.execute_reply.started":"2022-03-23T15:57:24.769597Z","shell.execute_reply":"2022-03-23T15:57:24.795432Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### K-fold CrossValidation for hyperparameters","metadata":{}},{"cell_type":"code","source":"import numpy  as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\n\nclass BlockingTimeSeriesSplit():\n    '''\n    1.Blockingbased sklearn.model_selection.TimeSeriesSplit\n    2.offer train_df and val_df into WindowGenerator\n    '''\n    def __init__(self, n_splits, X):\n        self.n_splits = n_splits\n        self.X = X\n    \n    def get_n_splits(self, X, y, groups):\n        return self.n_splits\n    \n    def split(self, X=None, y=None, groups=None):\n        x_none = getattr(self, 'X', None)\n        if x_none is not None:\n            n_samples = len(self.X)\n        else:\n            #in case of TimeSeriesSplit\n            n_samples = len(X)\n        k_fold_size = n_samples // self.n_splits\n        indices = np.arange(n_samples)\n\n        margin = 0\n        for i in range(self.n_splits):\n            start = i * k_fold_size\n            stop = start + k_fold_size\n            mid = int(0.5 * (stop - start)) + start\n            #return a generator\n            train_ind, test_ind = indices[start: mid], indices[mid + margin: stop]\n            yield train_ind, test_ind\n\n\n\n########################################visualize the split\ndef plot_cv_indices(cv, X,y=None, lw=10):\n    \"\"\"\n    Create a sample plot for indices of a cross-validation object.\n    https://goldinlocks.github.io/Time-Series-Cross-Validation/\n    \"\"\"\n    cmap_data = plt.cm.Paired\n    cmap_cv = plt.cm.coolwarm\n    fig, ax = plt.subplots(figsize=(10, 5))\n    # Generate the training/testing visualizations for each CV split\n    for ii, (tr, tt) in enumerate(cv.split(X=X)):\n        # Fill in indices with the training/test groups\n        indices = np.array([np.nan] * len(X))\n        indices[tt] = 1\n        indices[tr] = 0\n        # Visualize the results\n        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n                c=indices, marker='_', lw=lw, cmap=cmap_cv,\n                vmin=-.2, vmax=1.2)\n\n    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n            c=y, marker='_', lw=lw, cmap=cmap_data)\n    ax.set_title(f'{type(cv).__name__}', fontsize=15)\n    ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n        ['Testing set', 'Training set'], loc=(1.02, .8))\n    plt.tight_layout()\n    fig.subplots_adjust(right=.7)\n    plt.show()\n\n####################################test","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:02:09.649722Z","iopub.execute_input":"2022-03-23T16:02:09.650787Z","iopub.status.idle":"2022-03-23T16:02:10.913168Z","shell.execute_reply.started":"2022-03-23T16:02:09.650733Z","shell.execute_reply":"2022-03-23T16:02:10.911999Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\n\ntscv = TimeSeriesSplit(n_splits = 5)\nfor train_index, test_index in tscv.split(X=df):\n    cv_train, cv_test = df.iloc[train_index], df.iloc[test_index]\n    print(cv_train.shape,cv_test.shape)\n\nplot_cv_indices(tscv,X=df)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:50:17.379102Z","iopub.execute_input":"2022-03-23T15:50:17.379414Z","iopub.status.idle":"2022-03-23T15:52:35.235629Z","shell.execute_reply.started":"2022-03-23T15:50:17.379384Z","shell.execute_reply":"2022-03-23T15:52:35.234570Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"#from script.RNN.kfoldwindow import BlockingTimeSeriesSplit, plot_cv_indices\ntscv = BlockingTimeSeriesSplit(n_splits = 5, X=df)\nfor train_index, test_index in tscv.split(X=df):\n    cv_train, cv_test = df.iloc[train_index], df.iloc[test_index]\n    print(cv_train.shape,cv_test.shape)\nplot_cv_indices(tscv, X=tscv.X)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:52:43.229738Z","iopub.execute_input":"2022-03-23T14:52:43.230066Z","iopub.status.idle":"2022-03-23T14:52:47.335636Z","shell.execute_reply.started":"2022-03-23T14:52:43.230033Z","shell.execute_reply":"2022-03-23T14:52:47.334461Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"\n\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn import metrics\nimport itertools\n\ndef blockkfoldcv(df,K,model,withholdout:bool=True,holdoutpct=0.1):\n    '''\n    return the k-fold metrics on the model\n    '''\n    if withholdout:\n        #holdout/test sets\n        n = len(df)\n        test_df = df[int(n*(1-holdoutpct)):]\n        tscv = BlockingTimeSeriesSplit(n_splits = K,X=df[:int(n*(1-holdoutpct))])\n    else:\n        tscv = BlockingTimeSeriesSplit(n_splits = K,X=df)\n    fold = 0\n    oos_y = []\n    oos_pred = []\n    fold_score=[]\n    #k-fold loop\n    for train_index, val_index in tscv.split():\n        fold+=1\n        print(f\"Fold #{fold}\")\n        #train, validation sets in the fold\n        cv_train, cv_val = df.iloc[train_index], df.iloc[val_index]\n        num_features = df.shape[1]\n        #normalization\n        train_mean = cv_train.mean()\n        train_std = cv_train.std()\n        cv_train = (cv_train - train_mean) / train_std #scipy.stats.zscore(train_df,ddof=1)\n        cv_val = (cv_val - train_mean) / train_std\n        if withholdout:\n            test_df = (test_df - train_mean) / train_std\n        #fit model\n        wide_window,lstm_model = myfittedmodel(model=model,\n                                                input_width=30, label_width=30, shift=1,\n                                                train_df=cv_train, val_df=cv_val, test_df=test_df,\n                                                label_columns=['Close'],fit=True)\n\n        # Measure MSE error for this fold\n        score = lstm_model.evaluate(wide_window.val, verbose=0,return_dict=True)\n        fold_score.append(score['mse'])\n        print(f\"Fold score (MSE): {score['mse']}\")\n\n        # prediction on validation set\n        pred = []\n        label = []\n        for input_batch,label_batch in wide_window.val:\n            pred_batch = lstm_model(input_batch)\n            pred.append(list(pred_batch.numpy().flatten()))\n            label.append(list(label_batch.numpy().flatten()))\n        #flatten list of lists\n        pred = np.array(list(itertools.chain(*pred)))\n        label = np.array(list(itertools.chain(*label)))\n        oos_y.append(label)\n        oos_pred.append(pred) \n    # Build the oos prediction list and calculate the error.\n    oos_y = np.concatenate(oos_y)\n    oos_pred = np.concatenate(oos_pred)\n    oos_score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n    print(f\"Final, out of sample score (RMSE): {oos_score}\")  \n    return  oos_score","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:03:23.716233Z","iopub.execute_input":"2022-03-23T16:03:23.716544Z","iopub.status.idle":"2022-03-23T16:03:23.734251Z","shell.execute_reply.started":"2022-03-23T16:03:23.716512Z","shell.execute_reply":"2022-03-23T16:03:23.733364Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":"### Training with both a Cross-Validation and a Holdout Set","metadata":{}},{"cell_type":"code","source":"mylstm = mymodel()\nscore = blockkfoldcv(df = df, K=3,model=mylstm[0], withholdout=True,holdoutpct=0.1)\nIPython.display.clear_output()\n\nprint(f\"Final, out of sample score (RMSE): {score}\")  ","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:03:26.870306Z","iopub.execute_input":"2022-03-23T16:03:26.871469Z","iopub.status.idle":"2022-03-23T16:43:38.395113Z","shell.execute_reply.started":"2022-03-23T16:03:26.871399Z","shell.execute_reply":"2022-03-23T16:43:38.393792Z"},"trusted":true},"execution_count":124,"outputs":[]}]}