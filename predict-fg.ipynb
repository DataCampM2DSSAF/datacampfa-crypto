{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install jovian opendatasets matplotlib seaborn xgboost --upgrade --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-12T13:01:31.199481Z","iopub.execute_input":"2022-03-12T13:01:31.199766Z","iopub.status.idle":"2022-03-12T13:01:45.931981Z","shell.execute_reply.started":"2022-03-12T13:01:31.199735Z","shell.execute_reply":"2022-03-12T13:01:45.930912Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Import packages\nimport opendatasets as od\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\n\nfrom datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2022-03-12T13:01:49.719514Z","iopub.execute_input":"2022-03-12T13:01:49.719775Z","iopub.status.idle":"2022-03-12T13:01:51.484566Z","shell.execute_reply.started":"2022-03-12T13:01:49.719750Z","shell.execute_reply":"2022-03-12T13:01:51.483373Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Downloading the Data\nThe dataset is obtained from kaggle. The dataset contains information on historic trades for several cryptoassets, such as Bitcoin and Ethereum.","metadata":{}},{"cell_type":"code","source":"data_url = 'https://www.kaggle.com/c/g-research-crypto-forecasting/data'\nod.download(data_url)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:39:54.147414Z","iopub.execute_input":"2022-03-12T11:39:54.147704Z","iopub.status.idle":"2022-03-12T11:41:00.625423Z","shell.execute_reply.started":"2022-03-12T11:39:54.147671Z","shell.execute_reply":"2022-03-12T11:41:00.624279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = './g-research-crypto-forecasting'\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:42:19.986239Z","iopub.execute_input":"2022-03-12T11:42:19.987174Z","iopub.status.idle":"2022-03-12T11:42:19.991445Z","shell.execute_reply.started":"2022-03-12T11:42:19.987123Z","shell.execute_reply":"2022-03-12T11:42:19.990456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(data_dir)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:42:22.038118Z","iopub.execute_input":"2022-03-12T11:42:22.038422Z","iopub.status.idle":"2022-03-12T11:42:22.048597Z","shell.execute_reply.started":"2022-03-12T11:42:22.038376Z","shell.execute_reply":"2022-03-12T11:42:22.047818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read in Dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('./g-research-crypto-forecasting/train.csv')\nasset_details_df = pd.read_csv('./g-research-crypto-forecasting/asset_details.csv')\ntest_df = pd.read_csv('./g-research-crypto-forecasting/example_test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:42:28.569405Z","iopub.execute_input":"2022-03-12T11:42:28.569703Z","iopub.status.idle":"2022-03-12T11:43:07.208928Z","shell.execute_reply.started":"2022-03-12T11:42:28.569671Z","shell.execute_reply":"2022-03-12T11:43:07.208197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:16:59.073729Z","iopub.execute_input":"2022-03-12T12:16:59.074111Z","iopub.status.idle":"2022-03-12T12:16:59.093597Z","shell.execute_reply.started":"2022-03-12T12:16:59.074075Z","shell.execute_reply":"2022-03-12T12:16:59.092605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation and Cleaning\nThe training set has the following variables\n\ntimestamp - A timestamp for the minute covered by the row.\n\nAsset_ID - An ID code for the cryptoasset.\n\nCount - The number of trades that took place this minute.\n\nOpen - The USD price at the beginning of the minute.\n\nHigh - The highest USD price during the minute.\n\nLow - The lowest USD price during the minute.\n\nClose - The USD price at the end of the minute.\n\nVolume - The number of cryptoasset units traded during the minute.\n\nVWAP - The volume weighted average price for the minute.\n\nTarget - 15 minute residualized returns.\n\nThe following variables will be created based on the timestamp column.\n\nhour is the hour of the day\n\nweekday is the weekday of the week\n\nCategorical variables (Asset_ID, hour, and weekday) will be on hot encoded.\n\nNumeric variables (Count, Open, High, Low, Close, Volume, and VWAP) will be scaled to the value of 0 to 1 for each of the Asset_ID.","metadata":{}},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:27:05.651734Z","iopub.execute_input":"2022-03-12T12:27:05.652351Z","iopub.status.idle":"2022-03-12T12:27:05.658468Z","shell.execute_reply.started":"2022-03-12T12:27:05.652305Z","shell.execute_reply":"2022-03-12T12:27:05.657526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The training data has 24 million records and 10 columns","metadata":{}},{"cell_type":"markdown","source":"In order to reduce the data for lighter manipulation we take a subset up to November 2020","metadata":{}},{"cell_type":"code","source":"# Convert timestamp to date time\ntrain_df['timestamp'] = train_df.timestamp.astype('datetime64[s]')\ntrain_df = train_df[train_df.timestamp.dt.year==2020]\ntrain_df = train_df[train_df.timestamp.dt.month==11]\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:27:08.628247Z","iopub.execute_input":"2022-03-12T12:27:08.628683Z","iopub.status.idle":"2022-03-12T12:27:08.895934Z","shell.execute_reply.started":"2022-03-12T12:27:08.628623Z","shell.execute_reply":"2022-03-12T12:27:08.894936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The reduced training set has 598769 records.","metadata":{}},{"cell_type":"markdown","source":"## Handeling Missing Values\nCheck missing values","metadata":{}},{"cell_type":"code","source":"# check the timestamps for the assets with Asset_ID == 1\nl = []\nfor i in train_df.index:\n    if train_df['Asset_ID'][i] == 1:\n        l.append(train_df['timestamp'][i])\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:35:06.642658Z","iopub.execute_input":"2022-03-12T12:35:06.642956Z","iopub.status.idle":"2022-03-12T12:35:17.419151Z","shell.execute_reply.started":"2022-03-12T12:35:06.642923Z","shell.execute_reply":"2022-03-12T12:35:17.418288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:35:48.387627Z","iopub.execute_input":"2022-03-12T12:35:48.388304Z","iopub.status.idle":"2022-03-12T12:35:48.398427Z","shell.execute_reply.started":"2022-03-12T12:35:48.38826Z","shell.execute_reply":"2022-03-12T12:35:48.397553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data is updated every minute, but indeed some missing data appears. We will go around this issue in the Feature engineering part. Now we check if other variables are missing:","metadata":{}},{"cell_type":"code","source":"train_df.isna().sum()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:24:55.849495Z","iopub.execute_input":"2022-03-12T12:24:55.849807Z","iopub.status.idle":"2022-03-12T12:24:55.874785Z","shell.execute_reply.started":"2022-03-12T12:24:55.849772Z","shell.execute_reply":"2022-03-12T12:24:55.873913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 8814 records with missing data for the Target variable.","metadata":{}},{"cell_type":"code","source":"train_df.isin([np.nan, np.inf, -np.inf]).sum()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:24:59.150972Z","iopub.execute_input":"2022-03-12T12:24:59.151303Z","iopub.status.idle":"2022-03-12T12:25:04.510959Z","shell.execute_reply.started":"2022-03-12T12:24:59.151272Z","shell.execute_reply":"2022-03-12T12:25:04.509357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no infinity value in the data","metadata":{}},{"cell_type":"markdown","source":"The percentage of data without a Target value is low so we decide to ignore them. The following code will drop the missing values and infinity values.","metadata":{}},{"cell_type":"code","source":"train_df.dropna(inplace=True)\ntrain_df = train_df[np.isfinite(train_df).all(1)]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:25:08.057822Z","iopub.execute_input":"2022-03-12T12:25:08.058395Z","iopub.status.idle":"2022-03-12T12:25:08.158642Z","shell.execute_reply.started":"2022-03-12T12:25:08.058342Z","shell.execute_reply":"2022-03-12T12:25:08.157901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:25:10.541589Z","iopub.execute_input":"2022-03-12T12:25:10.542401Z","iopub.status.idle":"2022-03-12T12:25:10.770993Z","shell.execute_reply.started":"2022-03-12T12:25:10.542355Z","shell.execute_reply":"2022-03-12T12:25:10.769851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering\nThe following code converts timestamp to date time type and creates variables hour and weekday based on the value of column timestamp.","metadata":{}},{"cell_type":"code","source":"# Create hour variable\ntrain_df['hour'] = train_df.timestamp.dt.hour\n\n# Create weekday variable\ntrain_df['weekday'] = train_df.timestamp.dt.weekday","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:39:20.376381Z","iopub.execute_input":"2022-03-12T12:39:20.37675Z","iopub.status.idle":"2022-03-12T12:39:20.501301Z","shell.execute_reply.started":"2022-03-12T12:39:20.376715Z","shell.execute_reply":"2022-03-12T12:39:20.500405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode Categorical Variables\nThis section will convert variables Asset_ID, hour and weekday to categorical variables and create one hot encoder for categorical variables","metadata":{}},{"cell_type":"code","source":"# Convert Asset_ID, hour and weekday to categorical\ntrain_df['Asset_ID'] = train_df.Asset_ID.astype('category')\ntrain_df['hour'] = train_df.hour.astype('category')\ntrain_df['weekday'] = train_df.weekday.astype('category')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:39:53.615704Z","iopub.execute_input":"2022-03-12T12:39:53.615989Z","iopub.status.idle":"2022-03-12T12:39:53.646594Z","shell.execute_reply.started":"2022-03-12T12:39:53.61596Z","shell.execute_reply":"2022-03-12T12:39:53.645616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up Encoder\nencoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n\n# fit onehotcoder\nencoder.fit(train_df[['Asset_ID','hour','weekday']])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:39:58.116015Z","iopub.execute_input":"2022-03-12T12:39:58.116287Z","iopub.status.idle":"2022-03-12T12:39:58.176762Z","shell.execute_reply.started":"2022-03-12T12:39:58.116259Z","shell.execute_reply":"2022-03-12T12:39:58.175988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get new encoded cols names\nencoded_cols = list(encoder.get_feature_names(['Asset_ID','hour','weekday']))\n\n# replace categorical variables with one hot encoder\ntrain_df[encoded_cols] = encoder.transform(train_df[['Asset_ID','hour','weekday']])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:40:00.683695Z","iopub.execute_input":"2022-03-12T12:40:00.684263Z","iopub.status.idle":"2022-03-12T12:40:02.12842Z","shell.execute_reply.started":"2022-03-12T12:40:00.684221Z","shell.execute_reply":"2022-03-12T12:40:02.127294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scale Numeric Variables\nThis section will scale numeric variables Count, Open, High, Low, Close, Volume, and VWAP to range from 0 to 1.","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\n\nnum_cols = ['Count', 'Open', 'High', 'Low', 'Close', 'Volume', 'VWAP']\n\nscaler.fit(train_df[num_cols])\ntrain_df[num_cols] = scaler.transform(train_df[num_cols])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:40:08.911315Z","iopub.execute_input":"2022-03-12T12:40:08.912101Z","iopub.status.idle":"2022-03-12T12:40:09.440414Z","shell.execute_reply.started":"2022-03-12T12:40:08.912061Z","shell.execute_reply":"2022-03-12T12:40:09.439281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T12:40:22.561679Z","iopub.execute_input":"2022-03-12T12:40:22.56229Z","iopub.status.idle":"2022-03-12T12:40:22.599615Z","shell.execute_reply.started":"2022-03-12T12:40:22.562237Z","shell.execute_reply":"2022-03-12T12:40:22.59879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time Series Plots\nThe following code get the time range for each of the Asset_ID.","metadata":{}},{"cell_type":"code","source":"train_df.groupby([\"Asset_ID\"]).agg({'timestamp': [np.min,np.max]})\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:51:44.25101Z","iopub.execute_input":"2022-03-12T09:51:44.251319Z","iopub.status.idle":"2022-03-12T09:51:44.283344Z","shell.execute_reply.started":"2022-03-12T09:51:44.251285Z","shell.execute_reply":"2022-03-12T09:51:44.282454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The date range is slightly different for each of the asset.\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(50, 25))\nsns.lineplot(data=train_df, x=\"timestamp\", y=\"Target\", hue=\"Asset_ID\")","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:51:47.226056Z","iopub.execute_input":"2022-03-12T09:51:47.226472Z","iopub.status.idle":"2022-03-12T09:52:11.688488Z","shell.execute_reply.started":"2022-03-12T09:51:47.226441Z","shell.execute_reply":"2022-03-12T09:52:11.685375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Target variable has very different patterns for each of the asset of interest.","metadata":{}},{"cell_type":"markdown","source":"#### Correlation Matrix\nThe following code provide correlation matrix for each of the asset.","metadata":{}},{"cell_type":"code","source":"corr_matrix = train_df[['Count','Open','High','Low','Close','Volume','VWAP','Target']].corr()\nplt.figure(figsize=(10, 10))\nsns.heatmap(corr_matrix,annot=True, cmap='Blues');","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:52:16.762142Z","iopub.execute_input":"2022-03-12T09:52:16.76241Z","iopub.status.idle":"2022-03-12T09:52:17.509255Z","shell.execute_reply.started":"2022-03-12T09:52:16.762382Z","shell.execute_reply":"2022-03-12T09:52:17.508162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Open, High, Low, Close, and VWAP are highly correlated.","metadata":{}},{"cell_type":"markdown","source":"### Training and Testing Split\n\nUse data from November 1st - November 20th as training set, use the rest data in November as validation set. The testing set is provided in example_test.csv file.","metadata":{}},{"cell_type":"code","source":"train_set = train_df[train_df.timestamp.dt.day <= 20]\nval_set = train_df[train_df.timestamp.dt.day > 20]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:52:20.580421Z","iopub.execute_input":"2022-03-12T09:52:20.581773Z","iopub.status.idle":"2022-03-12T09:52:20.870939Z","shell.execute_reply.started":"2022-03-12T09:52:20.581695Z","shell.execute_reply":"2022-03-12T09:52:20.869896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:52:22.356167Z","iopub.execute_input":"2022-03-12T09:52:22.356511Z","iopub.status.idle":"2022-03-12T09:52:22.363821Z","shell.execute_reply.started":"2022-03-12T09:52:22.35647Z","shell.execute_reply":"2022-03-12T09:52:22.362842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_set.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:52:24.134309Z","iopub.execute_input":"2022-03-12T09:52:24.135205Z","iopub.status.idle":"2022-03-12T09:52:24.14207Z","shell.execute_reply.started":"2022-03-12T09:52:24.135153Z","shell.execute_reply":"2022-03-12T09:52:24.141222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set.Asset_ID.value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:52:25.827546Z","iopub.execute_input":"2022-03-12T09:52:25.829288Z","iopub.status.idle":"2022-03-12T09:52:25.860827Z","shell.execute_reply.started":"2022-03-12T09:52:25.829194Z","shell.execute_reply":"2022-03-12T09:52:25.859838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_set.Asset_ID.value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:52:27.77701Z","iopub.execute_input":"2022-03-12T09:52:27.777534Z","iopub.status.idle":"2022-03-12T09:52:27.791261Z","shell.execute_reply.started":"2022-03-12T09:52:27.777499Z","shell.execute_reply":"2022-03-12T09:52:27.789946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest\n\nThis section build random forest to predict the Target variable.","metadata":{}},{"cell_type":"code","source":"# Create the model\nrf1 = RandomForestRegressor(random_state=5, n_jobs = -1)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:52:29.637327Z","iopub.execute_input":"2022-03-12T09:52:29.637627Z","iopub.status.idle":"2022-03-12T09:52:29.643033Z","shell.execute_reply.started":"2022-03-12T09:52:29.637592Z","shell.execute_reply":"2022-03-12T09:52:29.642116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model\ninput_cols = num_cols + encoded_cols\ntarget_col = 'Target'\n\nrf1.fit(train_set[input_cols], train_set[target_col])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:52:33.260855Z","iopub.execute_input":"2022-03-12T09:52:33.261473Z","iopub.status.idle":"2022-03-12T09:59:10.300046Z","shell.execute_reply.started":"2022-03-12T09:52:33.261421Z","shell.execute_reply":"2022-03-12T09:59:10.298914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Evaluation\ntree_train_preds = rf1.predict(train_set[input_cols])\ntree_val_preds = rf1.predict(val_set[input_cols])\n\ntree_train_rmse = mean_squared_error(train_set[target_col], tree_train_preds, squared=False)\ntree_val_rmse = mean_squared_error(val_set[target_col], tree_val_preds, squared=False)\n\nprint(\"Train Error is \", tree_train_rmse)\nprint(\"Validation Error is \", tree_val_rmse)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:59:32.030924Z","iopub.execute_input":"2022-03-12T09:59:32.031265Z","iopub.status.idle":"2022-03-12T09:59:40.549809Z","shell.execute_reply.started":"2022-03-12T09:59:32.031224Z","shell.execute_reply":"2022-03-12T09:59:40.54883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# functions for hyperparameter tunning\ndef test_params(**params):\n    model = RandomForestRegressor(random_state=5, n_jobs=-1, **params).fit(train_set[input_cols], train_set[target_col])\n    train_rmse = mean_squared_error(model.predict(train_set[input_cols]), train_set[target_col], squared=False)\n    val_rmse = mean_squared_error(model.predict(val_set[input_cols]), val_set[target_col], squared=False)\n    return train_rmse, val_rmse\n\ndef test_param_and_plot(param_name, param_values):\n    train_errors, val_errors = [], [] \n    for value in param_values:\n        params = {param_name: value}\n        train_rmse, val_rmse = test_params(**params)\n        train_errors.append(train_rmse)\n        val_errors.append(val_rmse)\n    plt.figure(figsize=(10,6))\n    plt.title('Overfitting curve: ' + param_name)\n    plt.plot(param_values, train_errors, 'b-o')\n    plt.plot(param_values, val_errors, 'r-o')\n    plt.xlabel(param_name)\n    plt.ylabel('RMSE')\n    plt.legend(['Training', 'Validation'])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:59:59.270726Z","iopub.execute_input":"2022-03-12T09:59:59.271042Z","iopub.status.idle":"2022-03-12T09:59:59.282486Z","shell.execute_reply.started":"2022-03-12T09:59:59.271011Z","shell.execute_reply":"2022-03-12T09:59:59.281585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# max_depth\ntest_param_and_plot('max_depth', [5, 10, 15, 20, 25, 30, 35])","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:00:12.024221Z","iopub.execute_input":"2022-03-12T10:00:12.024525Z","iopub.status.idle":"2022-03-12T10:26:52.849055Z","shell.execute_reply.started":"2022-03-12T10:00:12.024493Z","shell.execute_reply":"2022-03-12T10:26:52.847876Z"},"trusted":true},"execution_count":null,"outputs":[]}]}